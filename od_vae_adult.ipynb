{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE outlier detection for income prediction\n",
    "\n",
    "### Method\n",
    "\n",
    "The Variational Auto-Encoder ([VAE](https://arxiv.org/abs/1312.6114)) outlier detector is first trained on a batch of unlabeled, but normal (inlier) data. Unsupervised training is desireable since labeled data is often scarce. The VAE detector tries to reconstruct the input it receives. If the input data cannot be reconstructed well, the reconstruction error is high and the data can be flagged as an outlier. The reconstruction error is measured as the mean squared error (MSE) between the input and the reconstructed instance.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "The instances contain a person's characteristics like age, marital status or education while the label represents whether the person makes more or less than $50k per year. The dataset consists of a mixture of numerical and categorical features. It is originally not an outlier detection dataset so we will inject artificial outliers. It is fetched using the [Alibi](https://github.com/SeldonIO/alibi) library, which can be installed with pip: \n",
    "\n",
    "```bash\n",
    "pip install alibi\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./models/od_vae_adult\n",
    "!mkdir -p ./models/od_vae_adult\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alibi\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()\n",
    "from tensorflow.keras.layers import Dense, InputLayer\n",
    "\n",
    "from alibi_detect.od import OutlierVAE\n",
    "from alibi_detect.utils.perturbation import inject_outlier_tabular\n",
    "from alibi_detect.utils.saving import save_detector, load_detector\n",
    "from alibi_detect.utils.visualize import plot_instance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(s=0):\n",
    "    np.random.seed(s)\n",
    "    tf.random.set_seed(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load adult dataset\n",
    "\n",
    "The ```fetch_adult``` function returns a ```Bunch``` object containing the features, the targets, the feature names and a mapping of the categories in each categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult = alibi.datasets.fetch_adult()\n",
    "X, y = adult.data, adult.target\n",
    "feature_names = adult.feature_names\n",
    "category_map_tmp = adult.category_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)\n",
    "Xy_perm = np.random.permutation(np.c_[X, y])\n",
    "X, y = Xy_perm[:,:-1], Xy_perm[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorganize data so categorical features come first, remove some features and adjust ```feature_names``` and ```category_map``` accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Education', 'Marital Status', 'Relationship', 'Age', 'Capital Gain', 'Capital Loss', 'Hours per week']\n"
     ]
    }
   ],
   "source": [
    "keep_cols = [2, 3, 5, 0, 8, 9, 10]\n",
    "feature_names = feature_names[2:4] + feature_names[5:6] + feature_names[0:1] + feature_names[8:11]\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 7)\n"
     ]
    }
   ],
   "source": [
    "X = X[:, keep_cols]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_map = {}\n",
    "i = 0\n",
    "for k, v in category_map_tmp.items():\n",
    "    if k in keep_cols:\n",
    "        category_map[i] = v\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data\n",
    "\n",
    "Normalize numerical features or scale numerical between -1 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num = X[:, -4:].astype(np.float32, copy=False)\n",
    "if minmax:\n",
    "    xmin, xmax = X_num.min(axis=0), X_num.max(axis=0)\n",
    "    rng = (-1., 1.)\n",
    "    X_num_scaled = (X_num - xmin) / (xmax - xmin) * (rng[1] - rng[0]) + rng[0]\n",
    "else:  # normalize\n",
    "    mu, sigma = X_num.mean(axis=0), X_num.std(axis=0)\n",
    "    X_num_scaled = (X_num - mu) / sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit OHE to categorical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cat = X[:, :-4].copy()\n",
    "ohe = OneHotEncoder(categories='auto')\n",
    "ohe.fit(X_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine numerical and categorical data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.c_[X_cat, X_num_scaled].astype(np.float32, copy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define train, validation (to find outlier threshold) and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 7) (25000,) (5000, 7) (5000,) (2561, 7) (2561,)\n"
     ]
    }
   ],
   "source": [
    "n_train = 25000\n",
    "n_valid = 5000\n",
    "X_train, y_train = X[:n_train,:], y[:n_train]\n",
    "X_valid, y_valid = X[n_train:n_train+n_valid,:], y[n_train:n_train+n_valid]\n",
    "X_test, y_test = X[n_train+n_valid:,:], y[n_train+n_valid:]\n",
    "print(X_train.shape, y_train.shape, \n",
    "      X_valid.shape, y_valid.shape,\n",
    "      X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create outliers\n",
    "\n",
    "Inject outliers in the numerical features. First we need to know the features for each kind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2] [3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "cat_cols = list(category_map.keys())\n",
    "num_cols = [col for col in range(X.shape[1]) if col not in cat_cols]\n",
    "print(cat_cols, num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical\n",
    "\n",
    "Now we can add outliers to the validation (or threshold) and test sets. For the numerical data, we need to specify the numerical columns (```cols```), the percentage of outliers (```perc_outlier```), the strength (```n_std```) and the minimum size of the perturbation (```min_std```). The outliers are distributed evenly across the numerical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.68% outliers\n"
     ]
    }
   ],
   "source": [
    "perc_outlier = 10\n",
    "data = inject_outlier_tabular(X_valid, num_cols, perc_outlier, n_std=8., min_std=6.)\n",
    "X_threshold, y_threshold = data.data, data.target\n",
    "X_threshold_, y_threshold_ = X_threshold.copy(), y_threshold.copy()  # store for comparison later\n",
    "outlier_perc = 100 * y_threshold.sum() / len(y_threshold)\n",
    "print('{:.2f}% outliers'.format(outlier_perc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect an instance that was changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age changed by -6.01.\n"
     ]
    }
   ],
   "source": [
    "outlier_idx = np.where(y_threshold != 0)[0]\n",
    "vdiff = X_threshold[outlier_idx[0]] - X_valid[outlier_idx[0]]\n",
    "fdiff = np.where(vdiff != 0)[0]\n",
    "print('{} changed by {:.2f}.'.format(feature_names[fdiff[0]], vdiff[fdiff[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same thing for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.64% outliers\n"
     ]
    }
   ],
   "source": [
    "data = inject_outlier_tabular(X_test, num_cols, perc_outlier, n_std=8., min_std=6.)\n",
    "X_outlier, y_outlier = data.data, data.target\n",
    "print('{:.2f}% outliers'.format(100 * y_outlier.sum() / len(y_outlier)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply one-hot encoding\n",
    "\n",
    "OHE to train, threshold and outlier sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 17) (5000, 17) (2561, 17)\n"
     ]
    }
   ],
   "source": [
    "X_train_ohe = ohe.transform(X_train[:, :-4].copy())\n",
    "X_threshold_ohe = ohe.transform(X_threshold[:, :-4].copy())\n",
    "X_outlier_ohe = ohe.transform(X_outlier[:, :-4].copy())\n",
    "print(X_train_ohe.shape, X_threshold_ohe.shape, X_outlier_ohe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 21) (5000, 21) (2561, 21)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.c_[X_train_ohe.todense(), X_train[:, -4:]].astype(np.float32, copy=False)\n",
    "X_threshold = np.c_[X_threshold_ohe.todense(), X_threshold[:, -4:]].astype(np.float32, copy=False)\n",
    "X_outlier = np.c_[X_outlier_ohe.todense(), X_outlier[:, -4:]].astype(np.float32, copy=False)\n",
    "print(X_train.shape, X_threshold.shape, X_outlier.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load or define outlier detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pretrained outlier and adversarial detectors used in the example notebooks can be found [here](https://console.cloud.google.com/storage/browser/seldon-models/alibi-detect). You can either manually download the relevant files in the [od_vae_adult](https://console.cloud.google.com/storage/browser/seldon-models/alibi-detect/od_vae_adult/) folder to e.g. the local directory ```my_dir```. Alternatively, if you have [Google Cloud SDK](https://cloud.google.com/sdk/docs/) installed, you can download the whole folder as follows:\n",
    "\n",
    "\n",
    "```bash\n",
    "!gsutil cp -r gs://seldon-models/alibi-detect/od_vae_kddcup my_dir\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_outlier_detector = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No threshold level set. Need to infer threshold using `infer_threshold`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [=] - 2s 5ms/step - loss: 0.2916\n",
      "391/391 [=] - 2s 5ms/step - loss: 0.2890\n",
      "391/391 [=] - 2s 5ms/step - loss: 0.2890\n",
      "391/391 [=] - 2s 5ms/step - loss: 0.2890\n",
      "391/391 [=] - 2s 5ms/step - loss: 0.2892\n"
     ]
    }
   ],
   "source": [
    "filepath = './models/od_vae_adult/'  # change to directory where model is downloaded\n",
    "if load_outlier_detector:  # load pretrained outlier detector\n",
    "    od = load_detector(filepath)\n",
    "else:  # define model, initialize, train and save outlier detector\n",
    "    n_features = X_train.shape[1]\n",
    "    latent_dim = 2\n",
    "\n",
    "    encoder_net = tf.keras.Sequential(\n",
    "      [\n",
    "          InputLayer(input_shape=(n_features,)),\n",
    "          Dense(25, activation=tf.nn.relu),\n",
    "          Dense(10, activation=tf.nn.relu),\n",
    "          Dense(5, activation=tf.nn.relu)\n",
    "      ])\n",
    "\n",
    "    decoder_net = tf.keras.Sequential(\n",
    "      [\n",
    "          InputLayer(input_shape=(latent_dim,)),\n",
    "          Dense(5, activation=tf.nn.relu),\n",
    "          Dense(10, activation=tf.nn.relu),\n",
    "          Dense(25, activation=tf.nn.relu),\n",
    "          Dense(n_features, activation=None)\n",
    "      ])\n",
    "    \n",
    "    # initialize outlier detector\n",
    "    od = OutlierVAE(threshold=None,  # threshold for outlier score\n",
    "                    score_type='mse',  # use MSE of reconstruction error for outlier detection\n",
    "                    encoder_net=encoder_net,  # can also pass VAE model instead\n",
    "                    decoder_net=decoder_net,  # of separate encoder and decoder\n",
    "                    latent_dim=latent_dim,\n",
    "                    samples=5)\n",
    "    \n",
    "    # train\n",
    "    od.fit(X_train,\n",
    "           loss_fn=tf.keras.losses.mse,\n",
    "           epochs=5,\n",
    "           verbose=True)\n",
    "\n",
    "    # save the trained outlier detector\n",
    "    save_detector(od, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The warning tells us we still need to set the outlier threshold. This can be done with the ```infer_threshold``` method. We need to pass a batch of instances and specify what percentage of those we consider to be normal via ```threshold_perc```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape too large to be a matrix.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [149]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_threshold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold_perc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43moutlier_perc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutlier_perc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNew threshold: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(od\u001b[38;5;241m.\u001b[39mthreshold))\n",
      "File \u001b[0;32m~/venv-income-outlier/lib/python3.8/site-packages/alibi_detect/od/vae.py:160\u001b[0m, in \u001b[0;36mOutlierVAE.infer_threshold\u001b[0;34m(self, X, outlier_type, outlier_perc, threshold_perc, batch_size)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03mUpdate threshold by a value inferred from the percentage of instances considered to be\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03moutliers in a sample of the dataset.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m    Batch size used when making predictions with the VAE.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# compute outlier scores\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m fscore, iscore \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutlier_perc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutlier_perc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outlier_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    162\u001b[0m     outlier_score \u001b[38;5;241m=\u001b[39m fscore\n",
      "File \u001b[0;32m~/venv-income-outlier/lib/python3.8/site-packages/alibi_detect/od/vae.py:239\u001b[0m, in \u001b[0;36mOutlierVAE.score\u001b[0;34m(self, X, outlier_perc, batch_size)\u001b[0m\n\u001b[1;32m    236\u001b[0m X_recon \u001b[38;5;241m=\u001b[39m predict_batch(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvae, X_samples, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# compute feature and instance level scores\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m fscore \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_recon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m iscore \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstance_score(fscore, outlier_perc\u001b[38;5;241m=\u001b[39moutlier_perc)\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fscore, iscore\n",
      "File \u001b[0;32m~/venv-income-outlier/lib/python3.8/site-packages/alibi_detect/od/vae.py:188\u001b[0m, in \u001b[0;36mOutlierVAE.feature_score\u001b[0;34m(self, X_orig, X_recon)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    187\u001b[0m     fscore \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpower(X_orig \u001b[38;5;241m-\u001b[39m X_recon, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 188\u001b[0m     fscore \u001b[38;5;241m=\u001b[39m \u001b[43mfscore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_orig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m     fscore \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(fscore, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproba\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/venv-income-outlier/lib/python3.8/site-packages/numpy/matrixlib/defmatrix.py:180\u001b[0m, in \u001b[0;36mmatrix.__array_finalize__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (ndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape too large to be a matrix.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     newshape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mValueError\u001b[0m: shape too large to be a matrix."
     ]
    }
   ],
   "source": [
    "od.infer_threshold(X_threshold, threshold_perc=100-outlier_perc, outlier_perc=100)\n",
    "print('New threshold: {}'.format(od.threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s save the outlier detector with updated threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_detector(od, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_preds = od.predict(X_outlier,\n",
    "                      outlier_type='instance',\n",
    "                      return_feature_score=True,\n",
    "                      return_instance_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display results\n",
    "\n",
    "F1 score and confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data.target_names\n",
    "y_pred = od_preds['data']['is_outlier']\n",
    "f1 = f1_score(y_outlier, y_pred)\n",
    "acc = accuracy_score(y_outlier, y_pred)\n",
    "prec = precision_score(y_outlier, y_pred)\n",
    "rec = recall_score(y_outlier, y_pred)\n",
    "print('F1 score: {:.2f} -- Accuracy: {:.2f} -- Precision: {:.2f} -- Recall: {:.2f}'.format(f1, acc, prec, rec))\n",
    "cm = confusion_matrix(y_outlier, y_pred)\n",
    "df_cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "sns.heatmap(df_cm, annot=True, cbar=True, linewidths=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot instance level outlier scores vs. the outlier threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_instance_score(od_preds, y_outlier.astype(int), labels, od.threshold, ylim=(0, 25))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
